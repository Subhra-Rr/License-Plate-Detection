import cv2
import numpy as np
from skimage.filters import threshold_local
import tensorflow as tf
from skimage import measure
import imutils
import os

# -------------------------------
# SORTING CHAR CONTOURS
# -------------------------------
def sort_cont(character_contours):
    boundingBoxes = [cv2.boundingRect(c) for c in character_contours]
    (character_contours, boundingBoxes) = zip(
        *sorted(zip(character_contours, boundingBoxes), key=lambda b: b[1][0])
    )
    return character_contours


# -------------------------------
# CHARACTER SEGMENTATION FUNCTION
# -------------------------------
def segment_chars(plate_img, fixed_width):
    V = cv2.split(cv2.cvtColor(plate_img, cv2.COLOR_BGR2HSV))[2]

    thresh = cv2.adaptiveThreshold(V, 255,
                                   cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                   cv2.THRESH_BINARY,
                                   11, 2)
    thresh = cv2.bitwise_not(thresh)

    plate_img = imutils.resize(plate_img, width=fixed_width)
    thresh = imutils.resize(thresh, width=fixed_width)
    bgr_thresh = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR)

    labels = measure.label(thresh, background=0)
    charCandidates = np.zeros(thresh.shape, dtype='uint8')

    characters = []

    for label in np.unique(labels):
        if label == 0:
            continue

        labelMask = np.zeros(thresh.shape, dtype='uint8')
        labelMask[labels == label] = 255

        cnts = cv2.findContours(labelMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cnts = cnts[0] if len(cnts) == 2 else cnts[1]

        if len(cnts) > 0:
            c = max(cnts, key=cv2.contourArea)
            (boxX, boxY, boxW, boxH) = cv2.boundingRect(c)

            aspectRatio = boxW / float(boxH)
            solidity = cv2.contourArea(c) / float(boxW * boxH)
            heightRatio = boxH / float(plate_img.shape[0])

            keepAspectRatio = aspectRatio < 1.0
            keepSolidity = solidity > 0.15
            keepHeight = 0.5 < heightRatio < 0.95

            if keepAspectRatio and keepSolidity and keepHeight and boxW > 14:
                hull = cv2.convexHull(c)
                cv2.drawContours(charCandidates, [hull], -1, 255, -1)

    contours, hier = cv2.findContours(charCandidates,
                                      cv2.RETR_EXTERNAL,
                                      cv2.CHAIN_APPROX_SIMPLE)

    if contours:
        contours = sort_cont(contours)

        addPixel = 4
        for c in contours:
            x, y, w, h = cv2.boundingRect(c)
            y = max(0, y - addPixel)
            x = max(0, x - addPixel)

            temp = bgr_thresh[y:y + h + (addPixel * 2),
                              x:x + w + (addPixel * 2)]
            characters.append(temp)

        return characters
    else:
        return None


# -------------------------------
# PLATE FINDER CLASS
# -------------------------------
class PlateFinder:
    def __init__(self, minPlateArea, maxPlateArea):
        self.min_area = minPlateArea
        self.max_area = maxPlateArea
        self.element_structure = cv2.getStructuringElement(
            shape=cv2.MORPH_RECT, ksize=(22, 3))

    def preprocess(self, input_img):
        imgBlurred = cv2.GaussianBlur(input_img, (7, 7), 0)
        gray = cv2.cvtColor(imgBlurred, cv2.COLOR_BGR2GRAY)
        sobelx = cv2.Sobel(gray, cv2.CV_8U, 1, 0, ksize=3)

        ret2, threshold_img = cv2.threshold(sobelx, 0, 255,
                                            cv2.THRESH_BINARY + cv2.THRESH_OTSU)

        morph_img = cv2.morphologyEx(threshold_img, cv2.MORPH_CLOSE,
                                     self.element_structure)
        return morph_img

    def extract_contours(self, after_preprocess):
        contours, _ = cv2.findContours(after_preprocess,
                                       cv2.RETR_EXTERNAL,
                                       cv2.CHAIN_APPROX_NONE)
        return contours

    def clean_plate(self, plate):
        gray = cv2.cvtColor(plate, cv2.COLOR_BGR2GRAY)
        thresh = cv2.adaptiveThreshold(gray, 255,
                                       cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                       cv2.THRESH_BINARY,
                                       11, 2)

        contours, _ = cv2.findContours(thresh.copy(),
                                       cv2.RETR_EXTERNAL,
                                       cv2.CHAIN_APPROX_NONE)

        if contours:
            areas = [cv2.contourArea(c) for c in contours]
            max_index = np.argmax(areas)
            max_cnt, max_area = contours[max_index], areas[max_index]

            x, y, w, h = cv2.boundingRect(max_cnt)

            if not self.ratioCheck(max_area, plate.shape[1], plate.shape[0]):
                return plate, False, None

            return plate, True, [x, y, w, h]

        return plate, False, None

    def validateRatio(self, rect):
        (x, y), (width, height), rect_angle = rect

        if width > height:
            angle = -rect_angle
        else:
            angle = 90 + rect_angle

        if angle > 15:
            return False

        if height == 0 or width == 0:
            return False

        area = width * height

        return self.preRatioCheck(area, width, height)

    def check_plate(self, input_img, contour):
        min_rect = cv2.minAreaRect(contour)

        if self.validateRatio(min_rect):
            x, y, w, h = cv2.boundingRect(contour)
            plate_region = input_img[y:y + h, x:x + w]
            clean_plate_img, found, coords = self.clean_plate(plate_region)

            if found:
                chars = self.find_characters_on_plate(clean_plate_img)

                if chars is not None and len(chars) == 8:
                    cx, cy, cw, ch = coords
                    coords = (cx + x, cy + y)
                    return clean_plate_img, chars, coords

        return None, None, None

    def find_possible_plates(self, input_img):
        plates = []
        self.char_on_plate = []
        self.corresponding_area = []

        processed = self.preprocess(input_img)
        contours = self.extract_contours(processed)

        for cnt in contours:
            plate, chars, coords = self.check_plate(input_img, cnt)

            if plate is not None:
                plates.append(plate)
                self.char_on_plate.append(chars)
                self.corresponding_area.append(coords)

        return plates if plates else None

    def find_characters_on_plate(self, plate):
        chars = segment_chars(plate, 400)
        return chars if chars else None

    # AREA / RATIO CHECKS
    def ratioCheck(self, area, width, height):
        ratio = max(width / float(height), height / float(width))
        return (self.min_area < area < self.max_area) and (3 < ratio < 6)

    def preRatioCheck(self, area, width, height):
        ratio = max(width / float(height), height / float(width))
        return (self.min_area < area < self.max_area) and (2.5 < ratio < 7)


# -------------------------------
# OCR CLASS
# -------------------------------
class OCR:
    def __init__(self, modelFile, labelFile):
        self.model_file = modelFile
        self.label_file = labelFile
        self.label = self.load_label(labelFile)
        self.graph = self.load_graph(modelFile)
        self.sess = tf.compat.v1.Session(graph=self.graph)

    def load_graph(self, modelFile):
        graph = tf.Graph()
        graph_def = tf.compat.v1.GraphDef()

        with open(modelFile, "rb") as f:
            graph_def.ParseFromString(f.read())

        with graph.as_default():
            tf.import_graph_def(graph_def)

        return graph

    def load_label(self, labelFile):
        with open(labelFile) as f:
            labels = [line.strip() for line in f]
        return labels

    def convert_tensor(self, image, size):
        image = cv2.resize(image, (size, size),
                           interpolation=cv2.INTER_CUBIC)
        np_img = cv2.normalize(image.astype('float'),
                               None, -0.5, .5,
                               cv2.NORM_MINMAX)
        return np.expand_dims(np_img, axis=0)

    def label_image(self, tensor):
        input_op = self.graph.get_operation_by_name("import/input")
        output_op = self.graph.get_operation_by_name("import/final_result")

        results = self.sess.run(output_op.outputs[0],
                                {input_op.outputs[0]: tensor})
        results = np.squeeze(results)
        return self.label[results.argmax()]

    def label_image_list(self, images, size):
        output = ""
        for img in images:
            output += self.label_image(self.convert_tensor(img, size))
        return output, len(output)


# -------------------------------
# MAIN PROGRAM
# -------------------------------
if __name__ == "__main__":

    findPlate = PlateFinder(minPlateArea=4100, maxPlateArea=15000)
    model = OCR(modelFile="model/binary_128_0.50_ver3.pb",
                labelFile="model/binary_128_0.50_labels_ver2.txt")

    cap = cv2.VideoCapture('test.MOV')

    while cap.isOpened():
        ret, frame = cap.read()

        if not ret:
            break

        cv2.imshow("original video", frame)

        if cv2.waitKey(25) & 0xFF == ord('q'):
            break

        plates = findPlate.find_possible_plates(frame)

        if plates:
            for i, p in enumerate(plates):
                chars = findPlate.char_on_plate[i]
                plate_text, _ = model.label_image_list(chars, 128)

                print(plate_text)
                cv2.imshow("plate", p)

                if cv2.waitKey(25) & 0xFF == ord('q'):
                    break

    cap.release()
    cv2.destroyAllWindows()
